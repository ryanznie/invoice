{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e56ef52",
   "metadata": {},
   "source": [
    "## INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd007420",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PIL'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LayoutLMv3ForQuestionAnswering, AutoProcessor\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'PIL'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import LayoutLMv3ForQuestionAnswering, AutoProcessor\n",
    "\n",
    "# 1️⃣ Load the model and processor\n",
    "model_path = \"models/layoutlmv3-finetuned-qa\"  # path to your finetuned model\n",
    "device = \"mps\"  # or \"cuda\" if you have GPU\n",
    "processor = AutoProcessor.from_pretrained(model_path)\n",
    "model = LayoutLMv3ForQuestionAnswering.from_pretrained(model_path).to(device)\n",
    "\n",
    "# 2️⃣ Load and parse test .txt file\n",
    "test_file = \"../data/SROIE2019/train/box/X00016469623.txt\"\n",
    "words = []\n",
    "bboxes = []\n",
    "\n",
    "with open(test_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        parts = line.split(\",\")\n",
    "        text = parts[-1]\n",
    "        # Use top-left and bottom-right coordinates for LayoutLMv3\n",
    "        x0, y0, x2, y2 = map(int, [parts[0], parts[1], parts[4], parts[5]])\n",
    "        words.append(text)\n",
    "        bboxes.append([x0, y0, x2, y2])\n",
    "\n",
    "# 3️⃣ Load image\n",
    "image_path = \"X00016469612.jpg\"  # replace with your image\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "image_width, image_height = image.size\n",
    "\n",
    "# 4️⃣ Normalize bboxes to [0, 1000]\n",
    "def normalize_bbox(bbox, width, height):\n",
    "    return [\n",
    "        int(1000 * bbox[0] / width),\n",
    "        int(1000 * bbox[1] / height),\n",
    "        int(1000 * bbox[2] / width),\n",
    "        int(1000 * bbox[3] / height),\n",
    "    ]\n",
    "\n",
    "norm_bboxes = [normalize_bbox(b, image_width, image_height) for b in bboxes]\n",
    "\n",
    "# 5️⃣ Prepare inputs for QA\n",
    "question = \"What is the invoice number?\"\n",
    "inputs = processor(\n",
    "    image,\n",
    "    words,\n",
    "    boxes=norm_bboxes,\n",
    "    question=question,\n",
    "    return_tensors=\"pt\",\n",
    ").to(device)\n",
    "\n",
    "# 6️⃣ Run inference\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    start_logits = outputs.start_logits\n",
    "    end_logits = outputs.end_logits\n",
    "\n",
    "# 7️⃣ Decode answer\n",
    "start_idx = start_logits.argmax(-1).item()\n",
    "end_idx = end_logits.argmax(-1).item()\n",
    "answer_tokens = inputs.input_ids[0][start_idx : end_idx + 1]\n",
    "answer = processor.tokenizer.decode(answer_tokens)\n",
    "\n",
    "print(\"Predicted Invoice Number:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2543175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
