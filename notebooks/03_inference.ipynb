{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c64276ea",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b65e1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LayoutLMv3ForTokenClassification were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label map: {0: 'B-INVOICE_ID', 1: 'I-INVOICE_ID', 2: 'O'}\n",
      "Detected entities:\n",
      "<s>: None\n",
      "TAN: I-INVOICE_ID\n",
      "CHAY: I-INVOICE_ID\n",
      "YEE: I-INVOICE_ID\n",
      "HO: I-INVOICE_ID\n",
      "TRADING: B-INVOICE_ID\n",
      "NO.2&4,JALAN: I-INVOICE_ID\n",
      "HARMONI: I-INVOICE_ID\n",
      "3/2,: B-INVOICE_ID\n",
      "TAMAN: I-INVOICE_ID\n",
      "DESA: I-INVOICE_ID\n",
      "HARMONI.: I-INVOICE_ID\n",
      "81100: I-INVOICE_ID\n",
      "JOHOR: B-INVOICE_ID\n",
      "BAHRU: B-INVOICE_ID\n",
      "JOHOR: B-INVOICE_ID\n",
      "07-355: I-INVOICE_ID\n",
      "2616: B-INVOICE_ID\n",
      "CASH: I-INVOICE_ID\n",
      "BILL: I-INVOICE_ID\n",
      ":: I-INVOICE_ID\n",
      "01-143008: I-INVOICE_ID\n",
      "DATE: I-INVOICE_ID\n",
      ":: I-INVOICE_ID\n",
      "09/01/2019: I-INVOICE_ID\n",
      "8:01:11: I-INVOICE_ID\n",
      "CASHIER: I-INVOICE_ID\n",
      ":: I-INVOICE_ID\n",
      "01: I-INVOICE_ID\n",
      "DESCRIPTION: I-INVOICE_ID\n",
      "QTY: I-INVOICE_ID\n",
      "PRICE: I-INVOICE_ID\n",
      "AMOUNT: I-INVOICE_ID\n",
      "RM: I-INVOICE_ID\n",
      "PLASTIC: I-INVOICE_ID\n",
      "31.00: I-INVOICE_ID\n",
      "31.00: I-INVOICE_ID\n",
      "TOTAL: I-INVOICE_ID\n",
      "AMOUNT:: I-INVOICE_ID\n",
      "31.00: I-INVOICE_ID\n",
      "CASH: I-INVOICE_ID\n",
      "RECEIVED: I-INVOICE_ID\n",
      ":: I-INVOICE_ID\n",
      "101.00: I-INVOICE_ID\n",
      "CHANGE: I-INVOICE_ID\n",
      ":: I-INVOICE_ID\n",
      "70.00: I-INVOICE_ID\n",
      "*GOODS: I-INVOICE_ID\n",
      "SOLD: I-INVOICE_ID\n",
      "ARE: I-INVOICE_ID\n",
      "NON-REFUNDABLE*: I-INVOICE_ID\n",
      "***THANK: I-INVOICE_ID\n",
      "YOU***: I-INVOICE_ID\n",
      "***PLEASE: I-INVOICE_ID\n",
      "COME: I-INVOICE_ID\n",
      "AGAIN***</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>: I-INVOICE_ID\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForTokenClassification\n",
    "from peft import PeftModel\n",
    "\n",
    "# -------------------------------\n",
    "# 1️⃣ Paths\n",
    "# -------------------------------\n",
    "base_model_name = \"microsoft/layoutlmv3-base\"\n",
    "lora_checkpoint = \"../models/layoutlmv3-finetuned-lora/checkpoint-2490\"\n",
    "train_json_path = \"../data/SROIE2019/train/train.json\"\n",
    "\n",
    "img_path = \"../data/SROIE2019/train/img/X00016469669.jpg\"\n",
    "ocr_path = \"../data/SROIE2019/train/box/X00016469669.txt\"\n",
    "\n",
    "# -------------------------------\n",
    "# 2️⃣ Load label map from training JSON\n",
    "# -------------------------------\n",
    "with open(train_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "all_labels = sorted({label for record in train_data for label in record.get(\"labels\", [])})\n",
    "id2label = {i: label for i, label in enumerate(all_labels)}\n",
    "label2id = {label: i for i, label in id2label.items()}\n",
    "\n",
    "print(\"Label map:\", id2label)\n",
    "\n",
    "# -------------------------------\n",
    "# 3️⃣ Load base model + LoRA adapter and merge\n",
    "# -------------------------------\n",
    "base_model = AutoModelForTokenClassification.from_pretrained(\n",
    "    base_model_name,\n",
    "    num_labels=len(id2label)\n",
    ")\n",
    "base_model.config.id2label = id2label\n",
    "base_model.config.label2id = label2id\n",
    "\n",
    "# Load adapter\n",
    "model = PeftModel.from_pretrained(base_model, lora_checkpoint)\n",
    "\n",
    "# Merge LoRA weights into base model for standard inference\n",
    "model = model.merge_and_unload()\n",
    "model.eval()\n",
    "\n",
    "# -------------------------------\n",
    "# 4️⃣ Load processor\n",
    "# -------------------------------\n",
    "processor = AutoProcessor.from_pretrained(base_model_name, apply_ocr=False)\n",
    "\n",
    "# -------------------------------\n",
    "# 5️⃣ OCR Parsing\n",
    "# -------------------------------\n",
    "def parse_ocr_file(txt_path):\n",
    "    words, bboxes = [], []\n",
    "    with open(txt_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\",\")\n",
    "            if len(parts) < 9:\n",
    "                continue\n",
    "            coords = list(map(int, parts[:8]))\n",
    "            text = \",\".join(parts[8:]).strip()\n",
    "            if not text:\n",
    "                continue\n",
    "            xs, ys = coords[::2], coords[1::2]\n",
    "            bbox = [min(xs), min(ys), max(xs), max(ys)]\n",
    "            words.append(text)\n",
    "            bboxes.append(bbox)\n",
    "    return words, bboxes\n",
    "\n",
    "def normalize_bbox(bbox, image_w, image_h):\n",
    "    x0, y0, x1, y1 = bbox\n",
    "    return [\n",
    "        int(1000 * (x0 / image_w)),\n",
    "        int(1000 * (y0 / image_h)),\n",
    "        int(1000 * (x1 / image_w)),\n",
    "        int(1000 * (y1 / image_h)),\n",
    "    ]\n",
    "\n",
    "def merge_tokens(tokens, labels):\n",
    "    words, word_labels = [], []\n",
    "    current_word, current_label = \"\", None\n",
    "    for token, label in zip(tokens, labels):\n",
    "        if token.startswith(\"Ġ\"):\n",
    "            if current_word:\n",
    "                words.append(current_word.strip())\n",
    "                word_labels.append(current_label)\n",
    "            current_word = token[1:]\n",
    "            current_label = label\n",
    "        else:\n",
    "            current_word += token\n",
    "    if current_word:\n",
    "        words.append(current_word.strip())\n",
    "        word_labels.append(current_label)\n",
    "    return list(zip(words, word_labels))\n",
    "\n",
    "# -------------------------------\n",
    "# 6️⃣ Load image + OCR\n",
    "# -------------------------------\n",
    "image = Image.open(img_path).convert(\"RGB\")\n",
    "words, bboxes = parse_ocr_file(ocr_path)\n",
    "img_w, img_h = image.size\n",
    "normalized_bboxes = [normalize_bbox(b, img_w, img_h) for b in bboxes]\n",
    "\n",
    "# -------------------------------\n",
    "# 7️⃣ Encode inputs\n",
    "# -------------------------------\n",
    "encoding = processor(\n",
    "    image,\n",
    "    words,\n",
    "    boxes=normalized_bboxes,\n",
    "    return_tensors=\"pt\",\n",
    "    truncation=True,\n",
    "    padding=\"max_length\",\n",
    "    max_length=512\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 8️⃣ Inference\n",
    "# -------------------------------\n",
    "with torch.no_grad():\n",
    "    outputs = model(**encoding)\n",
    "    predictions = outputs.logits.argmax(-1).squeeze().tolist()\n",
    "    tokens = processor.tokenizer.convert_ids_to_tokens(encoding[\"input_ids\"].squeeze())\n",
    "\n",
    "pred_labels = [model.config.id2label[p] for p in predictions]\n",
    "merged = merge_tokens(tokens, pred_labels)\n",
    "\n",
    "# -------------------------------\n",
    "# 9️⃣ Print clean results\n",
    "# -------------------------------\n",
    "print(\"Detected entities:\")\n",
    "for word, label in merged:\n",
    "    if label != \"O\":\n",
    "        print(f\"{word}: {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf31ad2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanznie/Desktop/work/invoice-ner/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py:1625: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>: None\n",
      "TAN: I-INVOICE_ID\n",
      "WOON: I-INVOICE_ID\n",
      "YANN: B-INVOICE_ID\n",
      "INDAH: I-INVOICE_ID\n",
      "GIFT: B-INVOICE_ID\n",
      "&: B-INVOICE_ID\n",
      "HOME: B-INVOICE_ID\n",
      "DECO: I-INVOICE_ID\n",
      "27,JALAN: B-INVOICE_ID\n",
      "DEDAP: B-INVOICE_ID\n",
      "13,: B-INVOICE_ID\n",
      "TAMAN: I-INVOICE_ID\n",
      "JOHOR: I-INVOICE_ID\n",
      "JAYA,: I-INVOICE_ID\n",
      "81100: B-INVOICE_ID\n",
      "JOHOR: I-INVOICE_ID\n",
      "BAHRU,JOHOR.: B-INVOICE_ID\n",
      "TEL:07-3507405: I-INVOICE_ID\n",
      "FAX:07-3558160: B-INVOICE_ID\n",
      "RECEIPT: B-INVOICE_ID\n",
      "19/10/2018: I-INVOICE_ID\n",
      "20:49:59: I-INVOICE_ID\n",
      "#01: I-INVOICE_ID\n",
      "CASHIER:: I-INVOICE_ID\n",
      "CN: I-INVOICE_ID\n",
      "LOCATION/SP:: B-INVOICE_ID\n",
      "05: B-INVOICE_ID\n",
      "/0531: B-INVOICE_ID\n",
      "MB:: I-INVOICE_ID\n",
      "MO26588: I-INVOICE_ID\n",
      "ROOM: B-INVOICE_ID\n",
      "NO:: I-INVOICE_ID\n",
      "01: I-INVOICE_ID\n",
      "050100035279: B-INVOICE_ID\n",
      "DESC/ITEM: I-INVOICE_ID\n",
      "QTY: I-INVOICE_ID\n",
      "PRICE: B-INVOICE_ID\n",
      "AMT(RM): I-INVOICE_ID\n",
      "ST-PRIVILEGE: I-INVOICE_ID\n",
      "CARD/GD: I-INVOICE_ID\n",
      "INDAH: B-INVOICE_ID\n",
      "88888: I-INVOICE_ID\n",
      "1: I-INVOICE_ID\n",
      "10.00: I-INVOICE_ID\n",
      "10.00: I-INVOICE_ID\n",
      "GF-TABLE: B-INVOICE_ID\n",
      "LAMP/STITCH: I-INVOICE_ID\n",
      "<I>: I-INVOICE_ID\n",
      "62483: I-INVOICE_ID\n",
      "1: B-INVOICE_ID\n",
      "55.90: B-INVOICE_ID\n",
      "55.90: B-INVOICE_ID\n",
      "@DISC: B-INVOICE_ID\n",
      "10.00%: I-INVOICE_ID\n",
      "-5.59: B-INVOICE_ID\n",
      "#TOTAL: B-INVOICE_ID\n",
      "QTY: I-INVOICE_ID\n",
      "2: B-INVOICE_ID\n",
      "TOTAL: B-INVOICE_ID\n",
      "AMT.................: I-INVOICE_ID\n",
      "RM: I-INVOICE_ID\n",
      "60.31: B-INVOICE_ID\n",
      "ROUNDING: B-INVOICE_ID\n",
      "ADJ............: I-INVOICE_ID\n",
      "-0.01: B-INVOICE_ID\n",
      "RM: B-INVOICE_ID\n",
      "60.30: B-INVOICE_ID\n",
      "CASH....................: I-INVOICE_ID\n",
      "RM: I-INVOICE_ID\n",
      "70.30: B-INVOICE_ID\n",
      "CHANGE..................: I-INVOICE_ID\n",
      "RM: I-INVOICE_ID\n",
      "10.00: B-INVOICE_ID\n",
      "THANK: B-INVOICE_ID\n",
      "YOU: B-INVOICE_ID\n",
      "!: B-INVOICE_ID\n",
      "PLEASE: B-INVOICE_ID\n",
      "COME: I-INVOICE_ID\n",
      "AGAIN: B-INVOICE_ID\n",
      "!: B-INVOICE_ID\n",
      "GOODS: B-INVOICE_ID\n",
      "SOLD: B-INVOICE_ID\n",
      "ARE: B-INVOICE_ID\n",
      "NOT: B-INVOICE_ID\n",
      "RETURNABLE: B-INVOICE_ID\n",
      "THANK: B-INVOICE_ID\n",
      "YOU: I-INVOICE_ID\n",
      "!: B-INVOICE_ID\n",
      "FLEASE: B-INVOICE_ID\n",
      "COME: I-INVOICE_ID\n",
      "AOSIN: B-INVOICE_ID\n",
      "!: B-INVOICE_ID\n",
      "GOODS: B-INVOICE_ID\n",
      "SOLD: B-INVOICE_ID\n",
      "ARE: I-INVOICE_ID\n",
      "NOT: B-INVOICE_ID\n",
      "RETURNABLE: B-INVOICE_ID\n",
      "DEALING: B-INVOICE_ID\n",
      "IN: B-INVOICE_ID\n",
      "WHOLESALE: B-INVOICE_ID\n",
      "AND: B-INVOICE_ID\n",
      "RETAIL.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>: B-INVOICE_ID\n"
     ]
    }
   ],
   "source": [
    "# --- Parse OCR file ---\n",
    "def parse_ocr_file(txt_path):\n",
    "    words, bboxes = [], []\n",
    "    with open(txt_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\",\")\n",
    "            if len(parts) < 9:\n",
    "                continue\n",
    "            coords = list(map(int, parts[:8]))\n",
    "            text = \",\".join(parts[8:]).strip()\n",
    "            if not text:\n",
    "                continue\n",
    "            xs, ys = coords[::2], coords[1::2]\n",
    "            bbox = [min(xs), min(ys), max(xs), max(ys)]\n",
    "            words.append(text)\n",
    "            bboxes.append(bbox)\n",
    "    return words, bboxes\n",
    "\n",
    "def normalize_bbox(bbox, image_w, image_h):\n",
    "    x0, y0, x1, y1 = bbox\n",
    "    return [\n",
    "        int(1000 * (x0 / image_w)),\n",
    "        int(1000 * (y0 / image_h)),\n",
    "        int(1000 * (x1 / image_w)),\n",
    "        int(1000 * (y1 / image_h)),\n",
    "    ]\n",
    "\n",
    "def merge_tokens(tokens, labels):\n",
    "    words, word_labels = [], []\n",
    "    current_word, current_label = \"\", None\n",
    "    for token, label in zip(tokens, labels):\n",
    "        if token.startswith(\"Ġ\"):\n",
    "            if current_word:\n",
    "                words.append(current_word.strip())\n",
    "                word_labels.append(current_label)\n",
    "            current_word = token[1:]\n",
    "            current_label = label\n",
    "        else:\n",
    "            current_word += token\n",
    "    if current_word:\n",
    "        words.append(current_word.strip())\n",
    "        word_labels.append(current_label)\n",
    "    return list(zip(words, word_labels))\n",
    "\n",
    "# --- Load image + OCR ---\n",
    "image = Image.open(img_path).convert(\"RGB\")\n",
    "words, bboxes = parse_ocr_file(ocr_path)\n",
    "img_w, img_h = image.size\n",
    "normalized_bboxes = [normalize_bbox(b, img_w, img_h) for b in bboxes]\n",
    "\n",
    "# --- Encode ---\n",
    "encoding = processor(\n",
    "    image,\n",
    "    words,\n",
    "    boxes=normalized_bboxes,\n",
    "    return_tensors=\"pt\",\n",
    "    truncation=True,\n",
    "    padding=\"max_length\",\n",
    "    max_length=512\n",
    ")\n",
    "\n",
    "# --- Inference ---\n",
    "with torch.no_grad():\n",
    "    outputs = model(**encoding)\n",
    "    predictions = outputs.logits.argmax(-1).squeeze().tolist()\n",
    "    tokens = processor.tokenizer.convert_ids_to_tokens(encoding[\"input_ids\"].squeeze())\n",
    "\n",
    "pred_labels = [model.config.id2label[p] for p in predictions]\n",
    "merged = merge_tokens(tokens, pred_labels)\n",
    "\n",
    "# --- Print results ---\n",
    "for word, label in merged:\n",
    "    if label != \"O\":\n",
    "        print(f\"{word}: {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f85873c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id2label: {0: 'B-INVOICE_ID', 1: 'I-INVOICE_ID', 2: 'O'}\n",
      "label2id: {'B-INVOICE_ID': 0, 'I-INVOICE_ID': 1, 'O': 2}\n"
     ]
    }
   ],
   "source": [
    "id2label = {i: label for i, label in enumerate(all_labels)}\n",
    "label2id = {label: i for i, label in id2label.items()}\n",
    "\n",
    "print(\"id2label:\", id2label)\n",
    "print(\"label2id:\", label2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e4e4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
