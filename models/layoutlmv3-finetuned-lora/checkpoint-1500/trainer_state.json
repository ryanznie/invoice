{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 6.024096385542169,
  "eval_steps": 500,
  "global_step": 1500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.040160642570281124,
      "grad_norm": 1.0997354984283447,
      "learning_rate": 9.963855421686748e-05,
      "loss": 1.1079,
      "step": 10
    },
    {
      "epoch": 0.08032128514056225,
      "grad_norm": 1.4330190420150757,
      "learning_rate": 9.923694779116465e-05,
      "loss": 0.9012,
      "step": 20
    },
    {
      "epoch": 0.12048192771084337,
      "grad_norm": 1.5424600839614868,
      "learning_rate": 9.883534136546186e-05,
      "loss": 0.6681,
      "step": 30
    },
    {
      "epoch": 0.1606425702811245,
      "grad_norm": 1.140687346458435,
      "learning_rate": 9.843373493975903e-05,
      "loss": 0.4703,
      "step": 40
    },
    {
      "epoch": 0.20080321285140562,
      "grad_norm": 0.8092164397239685,
      "learning_rate": 9.803212851405623e-05,
      "loss": 0.2669,
      "step": 50
    },
    {
      "epoch": 0.24096385542168675,
      "grad_norm": 0.18314705789089203,
      "learning_rate": 9.763052208835341e-05,
      "loss": 0.196,
      "step": 60
    },
    {
      "epoch": 0.28112449799196787,
      "grad_norm": 0.11601331830024719,
      "learning_rate": 9.722891566265061e-05,
      "loss": 0.1372,
      "step": 70
    },
    {
      "epoch": 0.321285140562249,
      "grad_norm": 0.5539779663085938,
      "learning_rate": 9.682730923694779e-05,
      "loss": 0.2032,
      "step": 80
    },
    {
      "epoch": 0.3614457831325301,
      "grad_norm": 0.24046380817890167,
      "learning_rate": 9.642570281124499e-05,
      "loss": 0.134,
      "step": 90
    },
    {
      "epoch": 0.40160642570281124,
      "grad_norm": 0.34604600071907043,
      "learning_rate": 9.602409638554217e-05,
      "loss": 0.1366,
      "step": 100
    },
    {
      "epoch": 0.44176706827309237,
      "grad_norm": 0.2568223476409912,
      "learning_rate": 9.562248995983937e-05,
      "loss": 0.1286,
      "step": 110
    },
    {
      "epoch": 0.4819277108433735,
      "grad_norm": 0.2686197757720947,
      "learning_rate": 9.522088353413655e-05,
      "loss": 0.2045,
      "step": 120
    },
    {
      "epoch": 0.5220883534136547,
      "grad_norm": 0.14388985931873322,
      "learning_rate": 9.481927710843373e-05,
      "loss": 0.1354,
      "step": 130
    },
    {
      "epoch": 0.5622489959839357,
      "grad_norm": 0.1617114096879959,
      "learning_rate": 9.441767068273092e-05,
      "loss": 0.1486,
      "step": 140
    },
    {
      "epoch": 0.6024096385542169,
      "grad_norm": 0.13776803016662598,
      "learning_rate": 9.401606425702811e-05,
      "loss": 0.1655,
      "step": 150
    },
    {
      "epoch": 0.642570281124498,
      "grad_norm": 0.16245731711387634,
      "learning_rate": 9.36144578313253e-05,
      "loss": 0.195,
      "step": 160
    },
    {
      "epoch": 0.6827309236947792,
      "grad_norm": 0.21531030535697937,
      "learning_rate": 9.321285140562249e-05,
      "loss": 0.1654,
      "step": 170
    },
    {
      "epoch": 0.7228915662650602,
      "grad_norm": 0.22920925915241241,
      "learning_rate": 9.281124497991968e-05,
      "loss": 0.1836,
      "step": 180
    },
    {
      "epoch": 0.7630522088353414,
      "grad_norm": 0.2796378433704376,
      "learning_rate": 9.240963855421687e-05,
      "loss": 0.1209,
      "step": 190
    },
    {
      "epoch": 0.8032128514056225,
      "grad_norm": 0.4657916724681854,
      "learning_rate": 9.200803212851406e-05,
      "loss": 0.1212,
      "step": 200
    },
    {
      "epoch": 0.8433734939759037,
      "grad_norm": 0.12807247042655945,
      "learning_rate": 9.160642570281125e-05,
      "loss": 0.1236,
      "step": 210
    },
    {
      "epoch": 0.8835341365461847,
      "grad_norm": 0.12265342473983765,
      "learning_rate": 9.120481927710844e-05,
      "loss": 0.1005,
      "step": 220
    },
    {
      "epoch": 0.9236947791164659,
      "grad_norm": 0.1255730539560318,
      "learning_rate": 9.080321285140563e-05,
      "loss": 0.1135,
      "step": 230
    },
    {
      "epoch": 0.963855421686747,
      "grad_norm": 0.25399622321128845,
      "learning_rate": 9.040160642570282e-05,
      "loss": 0.1212,
      "step": 240
    },
    {
      "epoch": 1.0040160642570282,
      "grad_norm": 0.24297946691513062,
      "learning_rate": 9e-05,
      "loss": 0.1012,
      "step": 250
    },
    {
      "epoch": 1.0441767068273093,
      "grad_norm": 0.23046301305294037,
      "learning_rate": 8.95983935742972e-05,
      "loss": 0.0772,
      "step": 260
    },
    {
      "epoch": 1.0843373493975903,
      "grad_norm": 0.2464030385017395,
      "learning_rate": 8.919678714859438e-05,
      "loss": 0.0907,
      "step": 270
    },
    {
      "epoch": 1.1244979919678715,
      "grad_norm": 0.18668003380298615,
      "learning_rate": 8.879518072289157e-05,
      "loss": 0.0928,
      "step": 280
    },
    {
      "epoch": 1.1646586345381527,
      "grad_norm": 0.25960659980773926,
      "learning_rate": 8.839357429718876e-05,
      "loss": 0.0934,
      "step": 290
    },
    {
      "epoch": 1.2048192771084336,
      "grad_norm": 0.36089345812797546,
      "learning_rate": 8.799196787148595e-05,
      "loss": 0.0774,
      "step": 300
    },
    {
      "epoch": 1.2449799196787148,
      "grad_norm": 0.18523791432380676,
      "learning_rate": 8.759036144578313e-05,
      "loss": 0.07,
      "step": 310
    },
    {
      "epoch": 1.285140562248996,
      "grad_norm": 0.40367916226387024,
      "learning_rate": 8.718875502008033e-05,
      "loss": 0.0702,
      "step": 320
    },
    {
      "epoch": 1.3253012048192772,
      "grad_norm": 0.5303566455841064,
      "learning_rate": 8.67871485943775e-05,
      "loss": 0.0678,
      "step": 330
    },
    {
      "epoch": 1.3654618473895583,
      "grad_norm": 0.1835150420665741,
      "learning_rate": 8.638554216867471e-05,
      "loss": 0.0695,
      "step": 340
    },
    {
      "epoch": 1.4056224899598393,
      "grad_norm": 0.18008920550346375,
      "learning_rate": 8.598393574297188e-05,
      "loss": 0.0487,
      "step": 350
    },
    {
      "epoch": 1.4457831325301205,
      "grad_norm": 0.9325887560844421,
      "learning_rate": 8.558232931726909e-05,
      "loss": 0.0945,
      "step": 360
    },
    {
      "epoch": 1.4859437751004017,
      "grad_norm": 0.1023697555065155,
      "learning_rate": 8.518072289156626e-05,
      "loss": 0.0588,
      "step": 370
    },
    {
      "epoch": 1.5261044176706826,
      "grad_norm": 0.2145661562681198,
      "learning_rate": 8.477911646586347e-05,
      "loss": 0.0508,
      "step": 380
    },
    {
      "epoch": 1.5662650602409638,
      "grad_norm": 0.25670406222343445,
      "learning_rate": 8.437751004016064e-05,
      "loss": 0.061,
      "step": 390
    },
    {
      "epoch": 1.606425702811245,
      "grad_norm": 0.3334185779094696,
      "learning_rate": 8.397590361445784e-05,
      "loss": 0.0471,
      "step": 400
    },
    {
      "epoch": 1.6465863453815262,
      "grad_norm": 0.1109081506729126,
      "learning_rate": 8.357429718875502e-05,
      "loss": 0.054,
      "step": 410
    },
    {
      "epoch": 1.6867469879518073,
      "grad_norm": 0.21703454852104187,
      "learning_rate": 8.317269076305221e-05,
      "loss": 0.0531,
      "step": 420
    },
    {
      "epoch": 1.7269076305220885,
      "grad_norm": 0.44986769556999207,
      "learning_rate": 8.27710843373494e-05,
      "loss": 0.0423,
      "step": 430
    },
    {
      "epoch": 1.7670682730923695,
      "grad_norm": 0.3799237608909607,
      "learning_rate": 8.236947791164659e-05,
      "loss": 0.0613,
      "step": 440
    },
    {
      "epoch": 1.8072289156626506,
      "grad_norm": 0.2406304031610489,
      "learning_rate": 8.196787148594378e-05,
      "loss": 0.0471,
      "step": 450
    },
    {
      "epoch": 1.8473895582329316,
      "grad_norm": 0.9183751344680786,
      "learning_rate": 8.156626506024097e-05,
      "loss": 0.0664,
      "step": 460
    },
    {
      "epoch": 1.8875502008032128,
      "grad_norm": 0.1286589652299881,
      "learning_rate": 8.116465863453816e-05,
      "loss": 0.0458,
      "step": 470
    },
    {
      "epoch": 1.927710843373494,
      "grad_norm": 0.20136843621730804,
      "learning_rate": 8.076305220883534e-05,
      "loss": 0.0418,
      "step": 480
    },
    {
      "epoch": 1.9678714859437751,
      "grad_norm": 0.10740706324577332,
      "learning_rate": 8.036144578313253e-05,
      "loss": 0.03,
      "step": 490
    },
    {
      "epoch": 2.0080321285140563,
      "grad_norm": 0.1058952808380127,
      "learning_rate": 7.995983935742972e-05,
      "loss": 0.0448,
      "step": 500
    },
    {
      "epoch": 2.0481927710843375,
      "grad_norm": 0.24176716804504395,
      "learning_rate": 7.955823293172691e-05,
      "loss": 0.0359,
      "step": 510
    },
    {
      "epoch": 2.0883534136546187,
      "grad_norm": 0.3678503632545471,
      "learning_rate": 7.91566265060241e-05,
      "loss": 0.0317,
      "step": 520
    },
    {
      "epoch": 2.1285140562248994,
      "grad_norm": 0.20136038959026337,
      "learning_rate": 7.875502008032129e-05,
      "loss": 0.0345,
      "step": 530
    },
    {
      "epoch": 2.1686746987951806,
      "grad_norm": 0.4237838089466095,
      "learning_rate": 7.835341365461848e-05,
      "loss": 0.0422,
      "step": 540
    },
    {
      "epoch": 2.208835341365462,
      "grad_norm": 0.841884434223175,
      "learning_rate": 7.795180722891567e-05,
      "loss": 0.0507,
      "step": 550
    },
    {
      "epoch": 2.248995983935743,
      "grad_norm": 0.5050318241119385,
      "learning_rate": 7.755020080321286e-05,
      "loss": 0.0276,
      "step": 560
    },
    {
      "epoch": 2.289156626506024,
      "grad_norm": 0.6458197832107544,
      "learning_rate": 7.714859437751005e-05,
      "loss": 0.0336,
      "step": 570
    },
    {
      "epoch": 2.3293172690763053,
      "grad_norm": 0.3301417827606201,
      "learning_rate": 7.674698795180724e-05,
      "loss": 0.0402,
      "step": 580
    },
    {
      "epoch": 2.3694779116465865,
      "grad_norm": 0.19046242535114288,
      "learning_rate": 7.634538152610443e-05,
      "loss": 0.0407,
      "step": 590
    },
    {
      "epoch": 2.4096385542168672,
      "grad_norm": 0.15934009850025177,
      "learning_rate": 7.594377510040162e-05,
      "loss": 0.0374,
      "step": 600
    },
    {
      "epoch": 2.4497991967871484,
      "grad_norm": 0.3712891936302185,
      "learning_rate": 7.55421686746988e-05,
      "loss": 0.0245,
      "step": 610
    },
    {
      "epoch": 2.4899598393574296,
      "grad_norm": 0.21216151118278503,
      "learning_rate": 7.514056224899598e-05,
      "loss": 0.0464,
      "step": 620
    },
    {
      "epoch": 2.5301204819277108,
      "grad_norm": 0.2159603387117386,
      "learning_rate": 7.473895582329318e-05,
      "loss": 0.033,
      "step": 630
    },
    {
      "epoch": 2.570281124497992,
      "grad_norm": 0.11030252277851105,
      "learning_rate": 7.433734939759036e-05,
      "loss": 0.0305,
      "step": 640
    },
    {
      "epoch": 2.610441767068273,
      "grad_norm": 0.396829217672348,
      "learning_rate": 7.393574297188756e-05,
      "loss": 0.0199,
      "step": 650
    },
    {
      "epoch": 2.6506024096385543,
      "grad_norm": 0.04512975737452507,
      "learning_rate": 7.353413654618474e-05,
      "loss": 0.0253,
      "step": 660
    },
    {
      "epoch": 2.6907630522088355,
      "grad_norm": 0.11919378489255905,
      "learning_rate": 7.313253012048194e-05,
      "loss": 0.0403,
      "step": 670
    },
    {
      "epoch": 2.7309236947791167,
      "grad_norm": 0.7726666331291199,
      "learning_rate": 7.273092369477912e-05,
      "loss": 0.0333,
      "step": 680
    },
    {
      "epoch": 2.7710843373493974,
      "grad_norm": 0.07177244871854782,
      "learning_rate": 7.232931726907632e-05,
      "loss": 0.0291,
      "step": 690
    },
    {
      "epoch": 2.8112449799196786,
      "grad_norm": 0.27916884422302246,
      "learning_rate": 7.19277108433735e-05,
      "loss": 0.0341,
      "step": 700
    },
    {
      "epoch": 2.8514056224899598,
      "grad_norm": 0.8268225789070129,
      "learning_rate": 7.152610441767068e-05,
      "loss": 0.0331,
      "step": 710
    },
    {
      "epoch": 2.891566265060241,
      "grad_norm": 0.14438408613204956,
      "learning_rate": 7.112449799196787e-05,
      "loss": 0.0227,
      "step": 720
    },
    {
      "epoch": 2.931726907630522,
      "grad_norm": 0.09670822322368622,
      "learning_rate": 7.072289156626506e-05,
      "loss": 0.025,
      "step": 730
    },
    {
      "epoch": 2.9718875502008033,
      "grad_norm": 0.0985882431268692,
      "learning_rate": 7.032128514056225e-05,
      "loss": 0.0234,
      "step": 740
    },
    {
      "epoch": 3.0120481927710845,
      "grad_norm": 0.2715780436992645,
      "learning_rate": 6.991967871485944e-05,
      "loss": 0.0213,
      "step": 750
    },
    {
      "epoch": 3.0522088353413657,
      "grad_norm": 0.28619638085365295,
      "learning_rate": 6.951807228915663e-05,
      "loss": 0.0196,
      "step": 760
    },
    {
      "epoch": 3.0923694779116464,
      "grad_norm": 0.3083443343639374,
      "learning_rate": 6.911646586345382e-05,
      "loss": 0.0268,
      "step": 770
    },
    {
      "epoch": 3.1325301204819276,
      "grad_norm": 0.18239940702915192,
      "learning_rate": 6.871485943775101e-05,
      "loss": 0.0166,
      "step": 780
    },
    {
      "epoch": 3.1726907630522088,
      "grad_norm": 0.34872329235076904,
      "learning_rate": 6.83132530120482e-05,
      "loss": 0.022,
      "step": 790
    },
    {
      "epoch": 3.21285140562249,
      "grad_norm": 0.808938205242157,
      "learning_rate": 6.791164658634539e-05,
      "loss": 0.0165,
      "step": 800
    },
    {
      "epoch": 3.253012048192771,
      "grad_norm": 0.5072485208511353,
      "learning_rate": 6.751004016064258e-05,
      "loss": 0.0358,
      "step": 810
    },
    {
      "epoch": 3.2931726907630523,
      "grad_norm": 0.1879962980747223,
      "learning_rate": 6.710843373493975e-05,
      "loss": 0.0192,
      "step": 820
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 0.16922570765018463,
      "learning_rate": 6.670682730923695e-05,
      "loss": 0.0128,
      "step": 830
    },
    {
      "epoch": 3.3734939759036147,
      "grad_norm": 0.19116787612438202,
      "learning_rate": 6.630522088353413e-05,
      "loss": 0.0207,
      "step": 840
    },
    {
      "epoch": 3.4136546184738954,
      "grad_norm": 0.26532819867134094,
      "learning_rate": 6.590361445783133e-05,
      "loss": 0.0187,
      "step": 850
    },
    {
      "epoch": 3.4538152610441766,
      "grad_norm": 0.1438378244638443,
      "learning_rate": 6.550200803212852e-05,
      "loss": 0.0139,
      "step": 860
    },
    {
      "epoch": 3.4939759036144578,
      "grad_norm": 0.15060514211654663,
      "learning_rate": 6.510040160642571e-05,
      "loss": 0.0137,
      "step": 870
    },
    {
      "epoch": 3.534136546184739,
      "grad_norm": 1.1150715351104736,
      "learning_rate": 6.46987951807229e-05,
      "loss": 0.0083,
      "step": 880
    },
    {
      "epoch": 3.57429718875502,
      "grad_norm": 0.17954625189304352,
      "learning_rate": 6.429718875502009e-05,
      "loss": 0.0143,
      "step": 890
    },
    {
      "epoch": 3.6144578313253013,
      "grad_norm": 1.1485178470611572,
      "learning_rate": 6.389558232931728e-05,
      "loss": 0.0171,
      "step": 900
    },
    {
      "epoch": 3.6546184738955825,
      "grad_norm": 0.45047399401664734,
      "learning_rate": 6.349397590361445e-05,
      "loss": 0.0239,
      "step": 910
    },
    {
      "epoch": 3.694779116465863,
      "grad_norm": 0.09024713188409805,
      "learning_rate": 6.309236947791166e-05,
      "loss": 0.0151,
      "step": 920
    },
    {
      "epoch": 3.734939759036145,
      "grad_norm": 0.038647182285785675,
      "learning_rate": 6.269076305220883e-05,
      "loss": 0.0115,
      "step": 930
    },
    {
      "epoch": 3.7751004016064256,
      "grad_norm": 0.4594738185405731,
      "learning_rate": 6.228915662650604e-05,
      "loss": 0.0118,
      "step": 940
    },
    {
      "epoch": 3.8152610441767068,
      "grad_norm": 0.12905435264110565,
      "learning_rate": 6.188755020080321e-05,
      "loss": 0.022,
      "step": 950
    },
    {
      "epoch": 3.855421686746988,
      "grad_norm": 0.9488304257392883,
      "learning_rate": 6.148594377510041e-05,
      "loss": 0.0236,
      "step": 960
    },
    {
      "epoch": 3.895582329317269,
      "grad_norm": 0.30409470200538635,
      "learning_rate": 6.108433734939759e-05,
      "loss": 0.013,
      "step": 970
    },
    {
      "epoch": 3.9357429718875503,
      "grad_norm": 0.27590280771255493,
      "learning_rate": 6.0682730923694785e-05,
      "loss": 0.0231,
      "step": 980
    },
    {
      "epoch": 3.9759036144578315,
      "grad_norm": 0.6034126877784729,
      "learning_rate": 6.028112449799197e-05,
      "loss": 0.0152,
      "step": 990
    },
    {
      "epoch": 4.016064257028113,
      "grad_norm": 0.3690722584724426,
      "learning_rate": 5.9879518072289164e-05,
      "loss": 0.012,
      "step": 1000
    },
    {
      "epoch": 4.056224899598393,
      "grad_norm": 0.1437559872865677,
      "learning_rate": 5.9477911646586346e-05,
      "loss": 0.0138,
      "step": 1010
    },
    {
      "epoch": 4.096385542168675,
      "grad_norm": 0.038515254855155945,
      "learning_rate": 5.9076305220883535e-05,
      "loss": 0.0091,
      "step": 1020
    },
    {
      "epoch": 4.136546184738956,
      "grad_norm": 0.017356252297759056,
      "learning_rate": 5.8674698795180725e-05,
      "loss": 0.0209,
      "step": 1030
    },
    {
      "epoch": 4.176706827309237,
      "grad_norm": 0.34493300318717957,
      "learning_rate": 5.8273092369477914e-05,
      "loss": 0.0144,
      "step": 1040
    },
    {
      "epoch": 4.216867469879518,
      "grad_norm": 0.027207208797335625,
      "learning_rate": 5.78714859437751e-05,
      "loss": 0.0192,
      "step": 1050
    },
    {
      "epoch": 4.257028112449799,
      "grad_norm": 0.09316883236169815,
      "learning_rate": 5.746987951807229e-05,
      "loss": 0.0147,
      "step": 1060
    },
    {
      "epoch": 4.2971887550200805,
      "grad_norm": 0.039358340203762054,
      "learning_rate": 5.706827309236948e-05,
      "loss": 0.011,
      "step": 1070
    },
    {
      "epoch": 4.337349397590361,
      "grad_norm": 0.07406370341777802,
      "learning_rate": 5.666666666666667e-05,
      "loss": 0.0062,
      "step": 1080
    },
    {
      "epoch": 4.377510040160643,
      "grad_norm": 0.13828614354133606,
      "learning_rate": 5.626506024096386e-05,
      "loss": 0.0168,
      "step": 1090
    },
    {
      "epoch": 4.417670682730924,
      "grad_norm": 0.3330947756767273,
      "learning_rate": 5.586345381526105e-05,
      "loss": 0.0115,
      "step": 1100
    },
    {
      "epoch": 4.457831325301205,
      "grad_norm": 0.14010509848594666,
      "learning_rate": 5.546184738955823e-05,
      "loss": 0.01,
      "step": 1110
    },
    {
      "epoch": 4.497991967871486,
      "grad_norm": 0.06422345340251923,
      "learning_rate": 5.506024096385543e-05,
      "loss": 0.0073,
      "step": 1120
    },
    {
      "epoch": 4.538152610441767,
      "grad_norm": 0.04769006371498108,
      "learning_rate": 5.465863453815261e-05,
      "loss": 0.0095,
      "step": 1130
    },
    {
      "epoch": 4.578313253012048,
      "grad_norm": 0.39416563510894775,
      "learning_rate": 5.4257028112449806e-05,
      "loss": 0.0193,
      "step": 1140
    },
    {
      "epoch": 4.618473895582329,
      "grad_norm": 0.3763667941093445,
      "learning_rate": 5.385542168674699e-05,
      "loss": 0.0183,
      "step": 1150
    },
    {
      "epoch": 4.658634538152611,
      "grad_norm": 0.44258221983909607,
      "learning_rate": 5.3453815261044185e-05,
      "loss": 0.0109,
      "step": 1160
    },
    {
      "epoch": 4.698795180722891,
      "grad_norm": 0.032818008214235306,
      "learning_rate": 5.305220883534137e-05,
      "loss": 0.014,
      "step": 1170
    },
    {
      "epoch": 4.738955823293173,
      "grad_norm": 0.23445093631744385,
      "learning_rate": 5.265060240963856e-05,
      "loss": 0.0145,
      "step": 1180
    },
    {
      "epoch": 4.779116465863454,
      "grad_norm": 0.05525276064872742,
      "learning_rate": 5.2248995983935745e-05,
      "loss": 0.0129,
      "step": 1190
    },
    {
      "epoch": 4.8192771084337345,
      "grad_norm": 0.1274401992559433,
      "learning_rate": 5.184738955823294e-05,
      "loss": 0.0147,
      "step": 1200
    },
    {
      "epoch": 4.859437751004016,
      "grad_norm": 0.09239552170038223,
      "learning_rate": 5.1445783132530124e-05,
      "loss": 0.0052,
      "step": 1210
    },
    {
      "epoch": 4.899598393574297,
      "grad_norm": 0.04652892425656319,
      "learning_rate": 5.1044176706827306e-05,
      "loss": 0.0113,
      "step": 1220
    },
    {
      "epoch": 4.9397590361445785,
      "grad_norm": 0.07636551558971405,
      "learning_rate": 5.06425702811245e-05,
      "loss": 0.0069,
      "step": 1230
    },
    {
      "epoch": 4.979919678714859,
      "grad_norm": 0.8012149930000305,
      "learning_rate": 5.0240963855421685e-05,
      "loss": 0.0237,
      "step": 1240
    },
    {
      "epoch": 5.020080321285141,
      "grad_norm": 0.11616640537977219,
      "learning_rate": 4.983935742971888e-05,
      "loss": 0.0243,
      "step": 1250
    },
    {
      "epoch": 5.0602409638554215,
      "grad_norm": 0.20426449179649353,
      "learning_rate": 4.943775100401606e-05,
      "loss": 0.01,
      "step": 1260
    },
    {
      "epoch": 5.100401606425703,
      "grad_norm": 0.21455571055412292,
      "learning_rate": 4.903614457831325e-05,
      "loss": 0.007,
      "step": 1270
    },
    {
      "epoch": 5.140562248995984,
      "grad_norm": 0.03315037488937378,
      "learning_rate": 4.863453815261044e-05,
      "loss": 0.0048,
      "step": 1280
    },
    {
      "epoch": 5.180722891566265,
      "grad_norm": 0.20422978699207306,
      "learning_rate": 4.823293172690763e-05,
      "loss": 0.0079,
      "step": 1290
    },
    {
      "epoch": 5.220883534136546,
      "grad_norm": 0.11009234935045242,
      "learning_rate": 4.783132530120482e-05,
      "loss": 0.009,
      "step": 1300
    },
    {
      "epoch": 5.261044176706827,
      "grad_norm": 0.11696502566337585,
      "learning_rate": 4.742971887550201e-05,
      "loss": 0.0049,
      "step": 1310
    },
    {
      "epoch": 5.301204819277109,
      "grad_norm": 0.03901469334959984,
      "learning_rate": 4.70281124497992e-05,
      "loss": 0.0166,
      "step": 1320
    },
    {
      "epoch": 5.341365461847389,
      "grad_norm": 0.03349129855632782,
      "learning_rate": 4.662650602409639e-05,
      "loss": 0.0053,
      "step": 1330
    },
    {
      "epoch": 5.381526104417671,
      "grad_norm": 0.27426818013191223,
      "learning_rate": 4.622489959839358e-05,
      "loss": 0.004,
      "step": 1340
    },
    {
      "epoch": 5.421686746987952,
      "grad_norm": 0.06882275640964508,
      "learning_rate": 4.5823293172690766e-05,
      "loss": 0.0042,
      "step": 1350
    },
    {
      "epoch": 5.461847389558233,
      "grad_norm": 0.52886563539505,
      "learning_rate": 4.542168674698795e-05,
      "loss": 0.0148,
      "step": 1360
    },
    {
      "epoch": 5.502008032128514,
      "grad_norm": 0.011637304909527302,
      "learning_rate": 4.502008032128514e-05,
      "loss": 0.0077,
      "step": 1370
    },
    {
      "epoch": 5.542168674698795,
      "grad_norm": 0.6450657844543457,
      "learning_rate": 4.461847389558233e-05,
      "loss": 0.0184,
      "step": 1380
    },
    {
      "epoch": 5.582329317269076,
      "grad_norm": 1.421633243560791,
      "learning_rate": 4.4216867469879516e-05,
      "loss": 0.0162,
      "step": 1390
    },
    {
      "epoch": 5.622489959839357,
      "grad_norm": 0.03103429637849331,
      "learning_rate": 4.3815261044176706e-05,
      "loss": 0.0093,
      "step": 1400
    },
    {
      "epoch": 5.662650602409639,
      "grad_norm": 0.02568615972995758,
      "learning_rate": 4.3413654618473895e-05,
      "loss": 0.0063,
      "step": 1410
    },
    {
      "epoch": 5.7028112449799195,
      "grad_norm": 0.20842388272285461,
      "learning_rate": 4.3012048192771084e-05,
      "loss": 0.0061,
      "step": 1420
    },
    {
      "epoch": 5.742971887550201,
      "grad_norm": 0.4279751777648926,
      "learning_rate": 4.261044176706827e-05,
      "loss": 0.0092,
      "step": 1430
    },
    {
      "epoch": 5.783132530120482,
      "grad_norm": 0.03239402547478676,
      "learning_rate": 4.220883534136546e-05,
      "loss": 0.0049,
      "step": 1440
    },
    {
      "epoch": 5.823293172690763,
      "grad_norm": 0.03743208944797516,
      "learning_rate": 4.180722891566265e-05,
      "loss": 0.0065,
      "step": 1450
    },
    {
      "epoch": 5.863453815261044,
      "grad_norm": 0.7525573372840881,
      "learning_rate": 4.140562248995984e-05,
      "loss": 0.0151,
      "step": 1460
    },
    {
      "epoch": 5.903614457831325,
      "grad_norm": 0.7381136417388916,
      "learning_rate": 4.100401606425703e-05,
      "loss": 0.0171,
      "step": 1470
    },
    {
      "epoch": 5.943775100401607,
      "grad_norm": 0.20716522634029388,
      "learning_rate": 4.060240963855422e-05,
      "loss": 0.019,
      "step": 1480
    },
    {
      "epoch": 5.983935742971887,
      "grad_norm": 0.023733286187052727,
      "learning_rate": 4.020080321285141e-05,
      "loss": 0.0097,
      "step": 1490
    },
    {
      "epoch": 6.024096385542169,
      "grad_norm": 0.4722154140472412,
      "learning_rate": 3.97991967871486e-05,
      "loss": 0.0058,
      "step": 1500
    }
  ],
  "logging_steps": 10,
  "max_steps": 2490,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 796223499264000.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
